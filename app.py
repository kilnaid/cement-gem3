import streamlit as st
import os
import time
from pinecone import Pinecone
from google import genai
from google.genai import types
from dotenv import load_dotenv

# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
load_dotenv()

def get_env(key):
    """ë°°í¬ í™˜ê²½(Secrets)ê³¼ ë¡œì»¬(.env) í™˜ê²½ ë³€ìˆ˜ í†µí•© ë¡œë“œ"""
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key)

# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •
st.set_page_config(
    page_title="Cement Expert AI (Gemini 3)",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

# 2. ë¡œê·¸ì¸ ì‹œìŠ¤í…œ
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def login_page():
    st.markdown("<h2 style='text-align: center;'>ğŸ—ï¸ Cement Expert AI Login</h2>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        with st.form("login_form"):
            uid = st.text_input("ID", placeholder="Manager ID")
            upw = st.text_input("Password", type="password", placeholder="Manager Password")
            if st.form_submit_button("ì‹œìŠ¤í…œ ì ‘ì†", use_container_width=True):
                if uid == "kilnaid" and upw == "1q2w3e4r":
                    st.session_state.logged_in = True
                    st.success("ì¸ì¦ ì„±ê³µ! ê³µì • ë¹„ì„œë¥¼ ê°€ë™í•©ë‹ˆë‹¤.")
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.error("âŒ ì˜ëª»ëœ ìê²© ì¦ëª…ì…ë‹ˆë‹¤.")

# 3. ë©”ì¸ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
def main_app():
    @st.cache_resource
    def init_clients():
        # Pinecone v6+ ë° Gemini 3 SDK ì´ˆê¸°í™”
        pc = Pinecone(api_key=get_env("PINECONE_API_KEY"))
        idx = pc.Index(get_env("PINECONE_INDEX_NAME"))
        g_client = genai.Client(api_key=get_env("GEMINI_API_KEY"))
        return idx, g_client

    index, client = init_clients()

    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë¨")
        st.info("ì—”ì§„: Gemini 3 Flash")
        st.markdown("---")
        st.markdown("**ë¶„ì„ ê°€ì´ë“œ:**")
        st.caption("- í•˜ì´ë¸Œë¦¬ë“œ ì§€ì‹ ê²°í•© (ë‚´ë¶€ ë¬¸ì„œ + ì‹¤ì‹œê°„ ì›¹)")
        st.caption("- ê³µì • ì¸ê³¼ê´€ê³„ ë° ì—´ì—­í•™ì  ì¶”ë¡ ")
        st.markdown("---")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.logged_in = False
            st.rerun()

    st.title("ğŸ—ï¸ ì‹œë©˜íŠ¸ ìƒì‚°Â·í’ˆì§ˆ ì§€ëŠ¥í˜• ë¹„ì„œ")
    st.caption("ğŸš€ Gemini 3 Flash & Multi-Document RAG Insight")

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ë°˜ê°‘ìŠµë‹ˆë‹¤, ê´€ë¦¬ìë‹˜. ì‹œë©˜íŠ¸ ìƒì‚° ë° í’ˆì§ˆ ì „ë°˜ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë§ì”€í•´ ì£¼ì„¸ìš”. ì „ë¬¸ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ë„ ìˆê²Œ ë¶„ì„í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."}
        ]

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê³µì • ì´ìŠˆë‚˜ ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ì „ë¬¸ ì§€ì‹ ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                try:
                    # [Step 1] ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€ (top_k=15)
                    # 42ê°œ ì´ìƒì˜ ë¬¸ì„œë¥¼ ì¶©ë¶„íˆ ê²€í† í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.
                    search_res = index.query(
                        data=prompt, 
                        top_k=15, 
                        include_metadata=True
                    )

                    context_text = ""
                    sources = set()
                    for match in search_res['matches']:
                        meta = match['metadata']
                        context_text += f"\n[ì¶œì²˜: {meta.get('source')} (P.{meta.get('page')})]\n{meta.get('text', '')}\n---"
                        sources.add(f"{meta.get('source')} (P.{int(meta.get('page', 0))})")

                    # [Step 2] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (í˜•ì‹ íŒŒê´´ ë° ê¹Šì´ ê°•ì¡°)
                    system_prompt = f"""
                    ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì„¸ê³„ ìµœê³  ì‹œë©˜íŠ¸ ê³µì • ë° í’ˆì§ˆ ê´€ë¦¬ ê¸°ìˆ  ê³ ë¬¸ì…ë‹ˆë‹¤.
                    ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ëŠ” ì±—ë´‡ì´ ì•„ë‹ˆë¼, ê´€ë¦¬ìì˜ ê³ ë¯¼ì— ëŒ€í•´ 'ì›ì¸-ì´ë¡ -í•´ê²°ì±…'ì˜ ìœ ê¸°ì ì¸ ì¸ê³¼ê´€ê³„ë¥¼ ê¿°ëš«ëŠ” ê¹Šì´ ìˆëŠ” í†µì°°ì„ ì œê³µí•˜ì„¸ìš”.

                    [ì‘ë‹µ ì§€ì¹¨]
                    1. **ì‹¬ì¸µì  ì¸ê³¼ê´€ê³„ ë¶„ì„**: í‘œë©´ì ì¸ í˜„ìƒë³´ë‹¤ ê·¸ ì´ë©´ì— ìˆ¨ê²¨ì§„ ì—´ì—­í•™ì , í™”í•™ì  ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í•˜ì„¸ìš”. Gemini 3ì˜ ë›°ì–´ë‚œ ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë³µí•©ì ì¸ ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
                    2. **í’ë¶€í•œ ì§€ì‹ í™œìš©**: ì œê³µëœ [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]ì„ ê¼¼ê¼¼íˆ ê²€í† í•˜ì—¬ ìˆ˜ì¹˜, í™”í•™ì‹, ì„¤ë¹„ ì‚¬ì–‘ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ë©° ì‹ ë¢°ë„ë¥¼ ë†’ì´ì„¸ìš”.
                    3. **ììœ ë¡œìš´ ì„œìˆ  í˜•ì‹**: ì–µì§€ë¡œ í¬ë§·ì„ ë§ì¶”ë ¤ í•˜ì§€ ë§ê³ , ì „ë¬¸ê°€ê°€ ëŒ€í™”í•˜ë“¯ ë…¼ë¦¬ì ì´ê³  ìœ ë ¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. í•„ìš”í•˜ë‹¤ë©´ í•­ëª©ë³„ ìš”ì•½ì„ ê³ë“¤ì´ë˜ ì „ì²´ì ì¸ ì„¤ëª…ì˜ ê¹Šì´ë¥¼ ìš°ì„ ì‹œí•˜ì„¸ìš”.
                    4. **í•˜ì´ë¸Œë¦¬ë“œ ì§€ì‹ ê²°í•©**: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ í™•ë³´í•œ ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œì™€ ë‹¹ì‹ ì˜ ê³µí•™ì  ì¶”ë¡ ì„ ê²°í•©í•˜ì—¬ ë‹µë³€ì„ ë³´ê°•í•˜ì„¸ìš”.
                    5. **ì „ë¬¸ê°€ì  ì œì–¸**: ê´€ë¦¬ìê°€ ë¯¸ì²˜ ìƒê°í•˜ì§€ ëª»í•œ ê³µì •ìƒì˜ ìœ ì—°ì„±(Buffer), ì„¤ë¹„ ì•ˆì •ì„±, ì›ë£Œ ê· ì¼ì„± ë“±ì˜ ê´€ì ì—ì„œë„ ì¡°ì–¸ì„ ì•„ë¼ì§€ ë§ˆì„¸ìš”.

                    [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]:
                    {context_text}
                    """

                    # [Step 3] Gemini 3 í˜¸ì¶œ (ì›¹ ê²€ìƒ‰ ë„êµ¬ í¬í•¨)
                    google_search_tool = types.Tool(google_search=types.GoogleSearch())
                    
                    response = client.models.generate_content(
                        model="gemini-3-flash",
                        contents=f"{system_prompt}\n\nì§ˆë¬¸: {prompt}",
                        config=types.GenerateContentConfig(
                            tools=[google_search_tool],
                            temperature=0.2 # ì•½ê°„ì˜ ì°½ì˜ì„±ê³¼ ìœ ì—°ì„±ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì†Œí­ ì¡°ì ˆ
                        )
                    )
                    
                    full_response = response.text
                    if sources:
                        full_response += "\n\n**ğŸ“Œ ë¶„ì„ ì°¸ì¡° ê¸°ìˆ  ë¬¸ì„œ:**\n- " + "\n- ".join(sorted(list(sources)))

                    st.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    st.error(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if not st.session_state.logged_in:
        login_page()
    else:
        main_app()

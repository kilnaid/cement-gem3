import streamlit as st
import os
import time
import io
from pinecone import Pinecone
from google import genai
from google.genai import types
from dotenv import load_dotenv
import pandas as pd
from PIL import Image

# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
load_dotenv()

def get_env(key):
    """ë°°í¬ í™˜ê²½(Secrets)ê³¼ ë¡œì»¬(.env) í™˜ê²½ ë³€ìˆ˜ í†µí•© ë¡œë“œ"""
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key)


def build_uploaded_file_context(uploaded_file):
    """ì—…ë¡œë“œ íŒŒì¼ ìš”ì•½(í‘œ) ë˜ëŠ” ì´ë¯¸ì§€ íŒŒíŠ¸ë¥¼ ìƒì„±í•´ ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
    if uploaded_file is None:
        return "", None

    file_name = uploaded_file.name
    file_bytes = uploaded_file.getvalue()
    ext = os.path.splitext(file_name)[1].lower()

    if ext in [".xlsx", ".xls", ".csv"]:
        try:
            if ext == ".csv":
                df = pd.read_csv(io.BytesIO(file_bytes))
                sheet_name = "csv"
            else:
                xls = pd.ExcelFile(io.BytesIO(file_bytes))
                sheet_name = xls.sheet_names[0]
                df = pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name)

            head_text = df.head(5).to_csv(index=False)
            col_preview = ", ".join(map(str, df.columns[:40]))
            context = (
                f"Uploaded file: {file_name}\n"
                f"Type: tabular\n"
                f"Sheet: {sheet_name}\n"
                f"Rows: {len(df)}, Columns: {len(df.columns)}\n"
                f"Columns preview: {col_preview}\n"
                f"Top 5 rows (CSV):\n{head_text}"
            )
            return context, None
        except Exception as e:
            return f"Uploaded tabular file parse failed: {file_name}, error: {e}", None

    if ext in [".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp"]:
        try:
            img = Image.open(io.BytesIO(file_bytes))
            mime = uploaded_file.type or "image/png"
            image_part = types.Part.from_bytes(data=file_bytes, mime_type=mime)
            context = (
                f"Uploaded file: {file_name}\n"
                f"Type: image\n"
                f"Image size: {img.width}x{img.height}, mode: {img.mode}\n"
                "Use this image as additional evidence for analysis."
            )
            return context, image_part
        except Exception as e:
            return f"Uploaded image parse failed: {file_name}, error: {e}", None

    return f"Unsupported uploaded file type: {file_name}", None

# ëª¨ë¸ ë° ì¸ë±ìŠ¤ ê·œê²© ì„¤ì •
EMBED_MODEL = "models/gemini-embedding-001"
CHAT_MODEL = "models/gemini-3-flash-preview"
TARGET_DIMENSION = 768  # ê´€ë¦¬ìë‹˜ì˜ Pinecone ì¸ë±ìŠ¤ ì°¨ì› ê·œê²©

st.set_page_config(page_title="Cement Expert AI (Deep Insight)", page_icon="ğŸ—ï¸", layout="wide")

# 2. ë¡œê·¸ì¸ ì‹œìŠ¤í…œ
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def login_page():
    st.markdown("<h2 style='text-align: center;'>ğŸ—ï¸ Cement Expert AI Login</h2>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        with st.form("login_form"):
            uid = st.text_input("ID", placeholder="Manager ID")
            upw = st.text_input("Password", type="password", placeholder="Manager Password")
            if st.form_submit_button("ì‹œìŠ¤í…œ ì ‘ì†", use_container_width=True):
                # ì‚¬ìš©ì ê³ ìœ  ê³„ì • ì •ë³´ í™œìš©
                if uid == "sampyo" and upw == "1q2w3e4r":
                    st.session_state.logged_in = True
                    st.rerun()
                else:
                    st.error("âŒ ìê²© ì¦ëª…ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# 3. ë©”ì¸ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
def main_app():
    @st.cache_resource
    def init_clients():
        # Pinecone ë° Gemini 3 SDK ì´ˆê¸°í™”
        pc = Pinecone(api_key=get_env("PINECONE_API_KEY"))
        idx = pc.Index(get_env("PINECONE_INDEX_NAME"))
        g_client = genai.Client(api_key=get_env("GEMINI_API_KEY"))
        return idx, g_client

    index, client = init_clients()

    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë¨ (RAG)")
        st.info(f"ì„ë² ë”©: {EMBED_MODEL} (768d)")
        uploaded_file = st.file_uploader(
            "Upload Excel/Image for current analysis",
            type=["xlsx", "xls", "csv", "png", "jpg", "jpeg", "bmp", "gif", "webp"],
            accept_multiple_files=False,
            help="The uploaded file is included as context in AI reasoning for your question.",
        )
        if uploaded_file is not None:
            st.success(f"Uploaded: {uploaded_file.name}")
        st.markdown("---")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.logged_in = False
            st.rerun()

    st.title("ğŸ—ï¸ ì‹œë©˜íŠ¸ ìƒì‚°Â·í’ˆì§ˆ ê¸°ìˆ  ê³ ë¬¸")
    st.caption(f"ğŸš€ {CHAT_MODEL} & Deep-Dive RAG Insight")

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë° ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ëŒ€í™” ê¸°ë¡ ì¶œë ¥ (UI)
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê³µì • ì´ìŠˆë‚˜ ì§€ë‚œ ëŒ€í™”ì— ì´ì–´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # 1. ì‚¬ìš©ì ì§ˆë¬¸ UI í‘œì‹œ ë° ì €ì¥
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ê³¼ê±° ëŒ€í™” ë§¥ë½ê³¼ 42ê°œ ì „ë¬¸ ë¬¸ì„œë¥¼ ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                try:
                    uploaded_context, uploaded_image_part = build_uploaded_file_context(uploaded_file)

                    # [Step 1] ìˆ˜ë™ ì„ë² ë”© ë° ê²€ìƒ‰ (ì°¨ì› ë¶ˆì¼ì¹˜ ì—ëŸ¬ í•´ê²°)
                    # output_dimensionalityë¥¼ ì„¤ì •í•˜ì—¬ 3072 -> 768ë¡œ ê°•ì œ ì¡°ì •í•©ë‹ˆë‹¤.
                    emb_res = client.models.embed_content(
                        model=EMBED_MODEL, 
                        contents=prompt,
                        config=types.EmbedContentConfig(output_dimensionality=TARGET_DIMENSION)
                    )
                    
                    search_res = index.query(
                        vector=emb_res.embeddings[0].values, 
                        top_k=15, 
                        include_metadata=True
                    )

                    context_text = ""
                    sources = set()
                    for match in search_res['matches']:
                        meta = match['metadata']
                        context_text += f"\n[ì¶œì²˜: {meta.get('source')} (P.{meta.get('page')})]\n{meta.get('text', '')}\n---"
                        sources.add(f"{meta.get('source')} (P.{int(meta.get('page', 0))})")

                    # [Step 2] ê³ ë„í™”ëœ ì‹œìŠ¤í…œ ì§€ì¹¨ êµ¬ì„±
                    system_instruction = f"""
                    ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì„¸ê³„ ìµœê³  ì‹œë©˜íŠ¸ ìƒì‚° ë° í’ˆì§ˆ ê´€ë¦¬ ê¸°ìˆ  ê³ ë¬¸ì…ë‹ˆë‹¤. 
                    ê´€ë¦¬ìì™€ì˜ ëŒ€í™” íë¦„ì„ ì™„ë²½íˆ íŒŒì•…í•˜ì—¬, ì´ì „ ì§ˆë¬¸ì—ì„œ ë‹¤ë£¬ ë§¥ë½ì„ ìœ ì§€í•˜ë©° ë‹µë³€í•˜ì„¸ìš”.

                    - ì´ë²ˆ ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ ë¬¸ì„œ ê·¼ê±°:
                    {context_text}

                    [í•„ìˆ˜ ì‘ë‹µ ì§€ì¹¨]
                    1. **ì‹¬ì¸µì  ì¸ê³¼ê´€ê³„ ë¶„ì„**: í‘œë©´ì ì¸ í˜„ìƒ(ì˜ˆ: f-CaO ìƒìŠ¹) ì´ë©´ì— ìˆ¨ê²¨ì§„ ì—´ì—­í•™ì , í™”í•™ì  ë©”ì»¤ë‹ˆì¦˜ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”. ë³µí•©ì ì¸ ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ì—¬ ê¸°ìˆ í•˜ì„¸ìš”.
                    2. **í’ë¶€í•œ ì§€ì‹ í™œìš©**: ì œê³µëœ [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]ì„ ê¼¼ê¼¼íˆ ê²€í† í•˜ì—¬ ìˆ˜ì¹˜, í™”í•™ì‹($CaO$, $C_3S$ ë“±), ì„¤ë¹„ ì‚¬ì–‘ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ë©° ì‹ ë¢°ë„ë¥¼ ë†’ì´ì„¸ìš”.
                    3. **ììœ ë¡­ê³  ìƒì„¸í•œ ì„œìˆ **: ì „ë¬¸ê°€ê°€ ì§ì ‘ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë“¯ ë…¼ë¦¬ì ì´ê³  ìœ ë ¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. ì „ì²´ì ì¸ ì„¤ëª…ì˜ ê¹Šì´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì—¬ ìµœì†Œ 1000ì ì´ìƒ ìƒì„¸íˆ ì„œìˆ í•˜ì„¸ìš”.
                    4. **í•˜ì´ë¸Œë¦¬ë“œ ì§€ì‹ ê²°í•©**: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ í™œìš©í•˜ê³ , ë‹¹ì‹ ì˜ ê³µí•™ì  ì¶”ë¡ ì„ ê²°í•©í•˜ì—¬ 'Deep Insight'ë¥¼ ì œê³µí•˜ì„¸ìš”.
                    5. **ì „ë¬¸ê°€ì  ì œì–¸**: ê´€ë¦¬ìê°€ ë¯¸ì²˜ ìƒê°í•˜ì§€ ëª»í•œ ê³µì •ìƒì˜ ìœ ì—°ì„±(Buffer), ì„¤ë¹„ ì•ˆì •ì„±, ì›ë£Œ ê· ì¼ì„± ë“±ì˜ ê´€ì ì—ì„œ ëŠ¥ë™ì ì¸ ì¡°ì–¸ì„ ì•„ë¼ì§€ ë§ˆì„¸ìš”.
                    """

                    # [Step 3] ëŒ€í™” ê¸°ë¡(History) ì¬êµ¬ì„±
                    chat_history = []
                    for m in st.session_state.messages[:-1]:
                        role = "user" if m["role"] == "user" else "model"
                        chat_history.append(types.Content(role=role, parts=[types.Part(text=m["content"])]))

                    # [Step 4] Gemini 3 ë‹µë³€ ìƒì„± (ì›¹ ê²€ìƒ‰ ë„êµ¬ í¬í•¨)
                    google_search_tool = types.Tool(google_search=types.GoogleSearch())

                    final_user_text = f"{system_instruction}\n\n"
                    if uploaded_context:
                        final_user_text += f"[Uploaded file context]\n{uploaded_context}\n\n"
                    final_user_text += f"ìµœì¢… ì§ˆë¬¸: {prompt}"

                    user_parts = [types.Part(text=final_user_text)]
                    if uploaded_image_part is not None:
                        user_parts.append(uploaded_image_part)
                    
                    response = client.models.generate_content(
                        model=CHAT_MODEL,
                        contents=chat_history + [
                            types.Content(role="user", parts=user_parts)
                        ],
                        config=types.GenerateContentConfig(
                            tools=[google_search_tool], 
                            temperature=0.4 # ì¶”ë¡ ì˜ ìœ ì—°ì„±ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì†Œí­ ì¡°ì •
                        )
                    )
                    
                    full_response = response.text
                    if sources:
                        full_response += "\n\n**ğŸ“Œ ì°¸ì¡° ë¬¸ì„œ:**\n- " + "\n- ".join(sorted(list(sources)))

                    st.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    st.error(f"âš ï¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if not st.session_state.logged_in:
        login_page()
    else:
        main_app()


import streamlit as st
import os
import time
from pinecone import Pinecone
from google import genai
from google.genai import types
from dotenv import load_dotenv

# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
load_dotenv()

def get_env(key):
    """ë°°í¬(Secrets)ì™€ ë¡œì»¬(.env) í™˜ê²½ ë³€ìˆ˜ í†µí•© ê´€ë¦¬"""
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key)

# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ë° ì œëª© ì„¤ì •
st.set_page_config(
    page_title="Cement Process Insight (Gemini 3)",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

# 2. ë¡œê·¸ì¸ ì‹œìŠ¤í…œ (ë³´ì•ˆ ì •ì±… ì ìš©)
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def login_page():
    st.markdown("<h2 style='text-align: center;'>ğŸ—ï¸ Cement Process Expert Login</h2>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        with st.form("login_form"):
            uid = st.text_input("ID", placeholder="Manager ID")
            upw = st.text_input("Password", type="password", placeholder="Manager Password")
            if st.form_submit_button("ì‹œìŠ¤í…œ ì ‘ì†", use_container_width=True):
                # ì‚¬ìš©ì ìš”ì•½ ì •ë³´ ê¸°ë°˜ ì¸ì¦
                if uid == "kilnaid" and upw == "1q2w3e4r":
                    st.session_state.logged_in = True
                    st.success("ì¸ì¦ ì„±ê³µ! ì „ë¬¸ ë³´ê³ ì„œ ì‹œìŠ¤í…œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.error("âŒ ìê²© ì¦ëª…ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# 3. ë©”ì¸ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
def main_app():
    @st.cache_resource
    def init_clients():
        # Pinecone ë° Gemini 3 ì „ìš© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        pc = Pinecone(api_key=get_env("PINECONE_API_KEY"))
        idx = pc.Index(get_env("PINECONE_INDEX_NAME"))
        g_client = genai.Client(api_key=get_env("GEMINI_API_KEY"))
        return idx, g_client

    index, client = init_clients()

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë¨ (v.004)")
        st.info("ì—”ì§„: Gemini 3 Flash Preview")
        st.markdown("---")
        st.markdown("**ë³´ê³ ì„œ ë¶„ì„ í•­ëª©:**")
        st.markdown("---")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.logged_in = False
            st.rerun()

    st.title("ğŸ—ï¸ ì‹œë©˜íŠ¸ ê³µì • ì§€ëŠ¥í˜• ë¶„ì„ ë¹„ì„œ")
    st.caption("ğŸš€ ì‹œë©˜íŠ¸ AIê°€ ë¶„ì„í•˜ëŠ” 3ë‹¨ê³„ ê¸°ìˆ  ë³´ê³ ì„œ ì‹œìŠ¤í…œ")

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ê´€ë¦¬ìë‹˜, ë¶„ì„ì´ í•„ìš”í•œ ì´ìŠˆë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”."}
        ]

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥ ë° ì²˜ë¦¬
    if prompt := st.chat_input("ì´ìŠˆë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í‚¬ë¥¸ í™”ì—¼ ì•ˆì •ì„± ì €í•˜ ì‹œ ì¡°ì¹˜ë²•)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ì „ë¬¸ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì›¹ ê²€ìƒ‰ì„ í†µí•´ ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # [Step 1] ì ì¬ëœ ë°ì´í„° í˜¸í™˜ ì„ë² ë”© (004 ëª¨ë¸ ì‚¬ìš©)
                    emb_res = client.models.embed_content(
                        model="models/text-embedding-004",
                        contents=prompt
                    )
                    query_vector = emb_res.embeddings[0].values

                    # [Step 2] Pinecone ë²¡í„° ê²€ìƒ‰
                    search_res = index.query(
                        vector=query_vector,
                        top_k=5,
                        include_metadata=True
                    )

                    context_text = ""
                    sources = set()
                    for match in search_res['matches']:
                        meta = match['metadata']
                        context_text += f"\n[ì¶œì²˜: {meta.get('source')} (P.{meta.get('page')})]\n{meta.get('text', '')}\n---"
                        sources.add(f"{meta.get('source')} (P.{int(meta.get('page', 0))})")

                    # [Step 3] ê³ ë„í™”ëœ ë³´ê³ ì„œí˜• ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
                    # ìˆ˜ì¹˜ ë° í™”í•™ì‹ í‘œí˜„ì„ ìœ„í•œ LaTeX ê°€ì´ë“œ í¬í•¨
                    system_prompt = f"""
                    ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì‹œë©˜íŠ¸ ê³µì • ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ê´€ë¦¬ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ 3ë‹¨ê³„ êµ¬ì¡°ì˜ ì „ë¬¸ ê¸°ìˆ  ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

                    ### 1. í˜„ìƒ ë¶„ì„ ë° ë¬¸ì œ ì›ì¸ íŒŒì•… (Problem & Causes)
                    - ì œê³µëœ [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]ê³¼ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í˜„ìƒì„ ì •ì˜í•˜ì„¸ìš”.
                    - ê·¼ë³¸ ì›ì¸(Root Causes)ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.
                    - ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë§¤ë‰´ì–¼ ì™¸ ìµœì‹  ê¸°ìˆ  ë™í–¥ ê²€ìƒ‰ ê²°ê³¼"ì„ì„ ëª…ì‹œí•˜ê³  ì„¤ëª…í•˜ì„¸ìš”.

                    ### 2. ê¸°ìˆ ì  ë°°ê²½ ë° ê´€ë ¨ ì´ë¡  (Technical Background)
                    - ì‹œë©˜íŠ¸ í™”í•™($CaO$, $C_3S$, $C_2S$, $C_3A$, $C_4AF$) ë° ì—´ì—­í•™ ì›ë¦¬ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
                    - Gemini 3ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ì‚¬ìš©í•˜ì—¬ ë³µí•©ì ì¸ ì¸ê³¼ê´€ê³„(ì˜ˆ: Burner í™•ì¥ê³¼ ì†Œì„± ì˜¨ë„ ìƒê´€ê´€ê³„)ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

                    ### 3. ê³µì • í˜„ì¥ ì ìš© ë°©ì•ˆ (Action Plan)
                    - ê´€ë¦¬ìê°€ í˜„ì¥ì—ì„œ ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì‹¤ë¬´ì  ëŒ€ì±…ì„ ì œì•ˆí•˜ì„¸ìš”.
                    - ì˜ˆìƒë˜ëŠ” ê°œì„  ê²°ê³¼ ë° ì£¼ì˜ì‚¬í•­ì„ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.

                    [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]:
                    {context_text}
                    """

                    # [Step 4] Gemini 3 í˜¸ì¶œ (ì›¹ ê²€ìƒ‰ ë„êµ¬ í†µí•©)
                    google_search_tool = types.Tool(google_search=types.GoogleSearch())
                    
                    response = client.models.generate_content(
                        model="gemini-3-flash-preview", 
                        contents=f"{system_prompt}\n\në¶„ì„ ìš”ì²­ ì‚¬í•­: {prompt}",
                        config=types.GenerateContentConfig(
                            tools=[google_search_tool],
                            temperature=0.1
                        )
                    )
                    
                    full_response = response.text
                    if sources:
                        full_response += "\n\n**ğŸ“Œ ì°¸ì¡° ê¸°ìˆ  ë¬¸ì„œ:**\n- " + "\n- ".join(sorted(list(sources)))

                    st.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    st.error(f"âš ï¸ ë³´ê³ ì„œ ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if not st.session_state.logged_in:
        login_page()
    else:
        main_app()

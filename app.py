import streamlit as st
import os
import time
from pinecone import Pinecone
from google import genai
from google.genai import types
from dotenv import load_dotenv

# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
load_dotenv()

def get_env(key):
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key)

st.set_page_config(page_title="Cement Expert AI (Full Memory)", page_icon="ğŸ—ï¸", layout="wide")

# 2. ë¡œê·¸ì¸ ì‹œìŠ¤í…œ (ê¸°ì¡´ ìœ ì§€)
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def login_page():
    st.markdown("<h2 style='text-align: center;'>ğŸ—ï¸ Cement Expert AI Login</h2>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        with st.form("login_form"):
            uid = st.text_input("ID", placeholder="Manager ID")
            upw = st.text_input("Password", type="password", placeholder="Manager Password")
            if st.form_submit_button("ì‹œìŠ¤í…œ ì ‘ì†", use_container_width=True):
                if uid == "kilnaid" and upw == "1q2w3e4r": #
                    st.session_state.logged_in = True
                    st.rerun()
                else:
                    st.error("âŒ ìê²© ì¦ëª…ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# 3. ë©”ì¸ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
def main_app():
    @st.cache_resource
    def init_clients():
        pc = Pinecone(api_key=get_env("PINECONE_API_KEY"))
        idx = pc.Index(get_env("PINECONE_INDEX_NAME"))
        g_client = genai.Client(api_key=get_env("GEMINI_API_KEY"))
        return idx, g_client

    index, client = init_clients()

    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë¨ (RAG)")
        st.info("ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬ í™œì„±í™” (Full History)")
        st.markdown("---")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.logged_in = False
            st.rerun()

    st.title("ğŸ—ï¸ ì‹œë©˜íŠ¸ ìƒì‚°Â·í’ˆì§ˆ ê¸°ìˆ  ê³ ë¬¸")
    st.caption("ğŸš€ Gemini 3 Flash & Multi-Turn Conversation Memory")

    # [ì¤‘ìš”] ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë° ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [] # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘ (ì²« ë©”ì‹œì§€ëŠ” ë£¨í”„ ë°–ì—ì„œ ì²˜ë¦¬)

    # ëŒ€í™” ê¸°ë¡ ì¶œë ¥ (UI)
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê³µì • ì´ìŠˆë‚˜ ì§€ë‚œ ëŒ€í™”ì— ì´ì–´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # 1. ì‚¬ìš©ì ì§ˆë¬¸ UI í‘œì‹œ ë° ì €ì¥
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ê³¼ê±° ëŒ€í™”ì™€ ì „ë¬¸ ë¬¸ì„œë¥¼ ì¢…í•© ë¶„ì„ ì¤‘..."):
                try:
                    # [Step 1] ìˆ˜ë™ ì„ë² ë”© ë° ê²€ìƒ‰ (400 ì—ëŸ¬ ë°©ì§€)
                    emb_res = client.models.embed_content(model="models/text-embedding-004", contents=prompt)
                    search_res = index.query(vector=emb_res.embeddings[0].values, top_k=15, include_metadata=True)

                    context_text = ""
                    sources = set()
                    for match in search_res['matches']:
                        meta = match['metadata']
                        context_text += f"\n[ì¶œì²˜: {meta.get('source')} (P.{meta.get('page')})]\n{meta.get('text', '')}\n---"
                        sources.add(f"{meta.get('source')} (P.{int(meta.get('page', 0))})")

                    # [Step 2] ì‹œìŠ¤í…œ ì§€ì¹¨ êµ¬ì„±
                    system_instruction = f"""
                    ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì‹œë©˜íŠ¸ ê¸°ìˆ  ê³ ë¬¸ì…ë‹ˆë‹¤. 
                    ê´€ë¦¬ìì™€ì˜ ëŒ€í™” íë¦„ì„ ì™„ë²½íˆ íŒŒì•…í•˜ì—¬, ì´ì „ ì§ˆë¬¸ì—ì„œ ë‹¤ë£¬ ë§¥ë½ì„ ìœ ì§€í•˜ë©° ë‹µë³€í•˜ì„¸ìš”.

                    - ì´ë²ˆ ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ ë¬¸ì„œ ê·¼ê±°:
                    {context_text}

                    [ì§€ì¹¨]
                    1. ê³¼ê±° ëŒ€í™”ì— ì–¸ê¸‰ëœ ì„¤ë¹„ë‚˜ íŠ¹ì • ìˆ˜ì¹˜ë¥¼ ê¸°ì–µí•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
                    2. í˜•ì‹ì— ì–½ë§¤ì´ì§€ ë§ê³ , ì „ë¬¸ê°€ê°€ ê¸°ìˆ  ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë“¯ ì‹¬ë„ ìˆê³  ìì„¸í•˜ê³ , ê¸¸ê²Œ ì„œìˆ í•˜ì„¸ìš”.
                    3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì›¹ ê²€ìƒ‰ê³¼ ë‹¹ì‹ ì˜ ê³µí•™ì  ì§€ì‹ì„ ê²°í•©í•˜ì—¬ í†µì°°ì„ ì œê³µí•˜ì„¸ìš”.
                    4. **ë§¥ë½ í™œìš©**: ì œê³µëœ [ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©]ì— í¬í•¨ëœ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë„í‘œ ë°ì´í„°ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬ ë‹µë³€ì˜ ì „ë¬¸ì„±ì„ ë†’ì´ì„¸ìš”.
                    5. **ìœ ì—°í•œ ì„œìˆ **: ì–µì§€ë¡œ í¬ë§·ì— ë§ì¶”ê¸°ë³´ë‹¤, ì „ë¬¸ê°€ê°€ ëŒ€í™”í•˜ë“¯ ë…¼ë¦¬ì ì´ê³  ìœ ë ¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                    6. **í•˜ì´ë¸Œë¦¬ë“œ ì§€ì‹**: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ êµ¬ê¸€ ê²€ìƒ‰ ì •ë³´ì™€ ë‹¹ì‹ ì˜ ê³µí•™ì  ì¶”ë¡ ì„ ê²°í•©í•˜ì—¬ 'Deep Insight'ë¥¼ ì œê³µí•˜ì„¸ìš”.
                    """

                    # [Step 3] ëŒ€í™” ê¸°ë¡(History) ì¬êµ¬ì„± (Gemini API í˜•ì‹ì— ë§ì¶¤)
                    # ê³¼ê±° ë©”ì‹œì§€ë“¤ì„ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœì˜ 'contents' ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                    chat_history = []
                    for m in st.session_state.messages[:-1]: # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì œì™¸í•œ ê³¼ê±° ê¸°ë¡
                        role = "user" if m["role"] == "user" else "model"
                        chat_history.append(types.Content(role=role, parts=[types.Part(text=m["content"])]))

                    # [Step 4] ë‹µë³€ ìƒì„± (ì „ì²´ íˆìŠ¤í† ë¦¬ + ì‹œìŠ¤í…œ ì§€ì¹¨ + í˜„ì¬ ì§ˆë¬¸)
                    google_search_tool = types.Tool(google_search=types.GoogleSearch())
                    
                    response = client.models.generate_content(
                        model="gemini-3-flash-preview",
                        contents=chat_history + [
                            types.Content(role="user", parts=[types.Part(text=f"{system_instruction}\n\nìµœì¢… ì§ˆë¬¸: {prompt}")])
                        ],
                        config=types.GenerateContentConfig(tools=[google_search_tool], temperature=0.3)
                    )
                    
                    full_response = response.text
                    if sources:
                        full_response += "\n\n**ğŸ“Œ ì°¸ì¡° ë¬¸ì„œ:**\n- " + "\n- ".join(sorted(list(sources)))

                    st.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    st.error(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if not st.session_state.logged_in: login_page()
    else: main_app()
